agent_model:
  name: "Qwen/Qwen3-1.7B"
  type: "qwen"
  temperature: 0.7
  top_p: 0.9
  max_length: 2048
  torch_dtype: "auto"

agents: null

critic_model:
  name: "Qwen/Qwen3-1.7B"
  type: "qwen"
  temperature: 0.7
  top_p: 0.9
  max_length: 2048
  torch_dtype: "auto"

critics: null

dataset:
  name: "trl-lib/tldr"
  type: "tldr"
  train_split: "train[:1000]"
  eval_split: "test[:1000]"

tokenizer:
  padding_side: "left"

output:
  base_dir: "./iac_output"
  verbose: false
  save_final_model: true
  save_path: "./iac_output/iac_tldr"

iac:
  num_agents: 2
  num_turns: 1
  num_train_epochs: 20
  agent_learning_rate: 5.0e-6
  critic_learning_rate: 5.0e-6
  value_loss_coef: 0.6
  value_clip_range: 0.2
  rollout_buffer_size: 4
  train_batch_size: 4
  max_new_tokens: 256
  temperature: 0.7
  top_p: 0.9
  top_k: null
  eval_interval: 20
  eval_num_samples: 4
  eval_batch_size: 1
  logging_steps: 50

reward_processor:
  enabled: true
  scale_factor: 1.0
  shift: 0.0

wandb:
  project: "comlrl"
  entity: "OpenMLRL"
  name: "iac_tldr"
  tags: ["iac", "tldr", "multi-agent"]
